---
title: "Data Preparation"
output: 
  html_document: 
    fig_caption: yes
    toc: yes
    toc_float: true
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
options(tibble.print_min = 5)

homes <- read_csv("http://people.virginia.edu/~jah2ax/intro_to_R_spring_2019/albemarle_real_estate.csv")
```

# Get Ready!

Download the data files and R scripts:

* [Download this zipped folder.](http://static.lib.virginia.edu/statlab/materials/workshops/dataprepR.zip) It contains two data files (CAMA_CardLevelData.txt, CAMA_ParcelInfo.txt) and two R scripts (intro_dplyr.R and data_prep.R)
* Unzip it and put it somwehere you can locate it on your machine.

# Data Preparation and Tidy Data

Data is usually messy and requires preparation (aka cleaning, wrangling, munging). You can approach data preparation as tedious ["janitorial work"](https://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html)^[Way to be classist NYT...] or as an opportunity to really get to know your data -- it's possibility and limitations, quirks and errors. We'll use the Albemarle County Real Estate data to as an in-depth example, getting it ready for more complex visualizations and analysis to come.

Before we dive in with the data, let's get to know the `dplyr` package. Part of the the [`tidyverse`](https://www.tidyverse.org/), [`dplyr`](https://dplyr.tidyverse.org/)  is a package for data manipulation. The package implements a *grammar* for transforming data, based on verbs/functions that define a set of common tasks.


## Functions/Verbs

`dplyr` functions are for `d`ata frames

* first argument of `dplyr` functions is always a data frame
* followed by function specific arguments that detail what to do
* returns a data frame

# dplyr: Isolating data

<center>
$\color{blue}{\text{select()}}$ - extract $\color{blue}{\text{variables}}$ 

$\color{green}{\text{filter()}}$ - extract $\color{green}{\text{rows}}$

$\color{green}{\text{arrange()}}$ - reorder $\color{green}{\text{rows}}$

</center>

Let's look at some quick examples using the `homes` data from last week.

## select()
Extract columns by name

```{r}
select(homes, TotalValue)
select(homes, TotalValue, City)
```

select() helpers include

* select(.data, **var1:var10**): select range of columns
* select(.data, **-c(var1, var2)**): select every column but
* select(.data, **starts_with("string")**): select columns that start with...
* select(.data, **contains("string")**): select columns whose names contain...

```{r}
select(homes, LotSize:City)
select(homes, -c(LotSize:City))
select(homes, contains("Year"))
```

## filter()
Extract rows that meet logical condition

```{r}
filter(homes, YearBuilt == 2016)
```

Logical tests

* x **<** y: less than
* x **>** y: greater than
* x **==** y: equal to
* x **<-** y: less than or equal to
* y **>=** y: greater than or equal to
* x **!=** y: not equal to
* x **%in%** y: is a member of
* **is.na(**x**)**: is NA
* **!is.na(**x**)**: is not NA

```{r}
filter(homes, YearRemodeled > 0)
filter(homes, Bedroom == max(Bedroom))
filter(homes, City %in% c("SCOTTSVILLE", "CROZET"))
```

Boolean operators for multiple conditions

* a **&** b: and
* a **|** b: or
* **xor(**a,b**)**: exactly or
* **!**a: not

```{r}
filter(homes, City == "SCOTTSVILLE" & FinSqFt > mean(FinSqFt))
```


## arrange()
Order rows from smallest to largest values for designated column/s.

```{r}
arrange(homes, FinSqFt)
```

* **desc()**: reverses order, largest to smallest.

```{r}
arrange(homes, desc(FinSqFt))
```

## and more...

<center>

$\color{green}{\text{slice()}}$ - extract $\color{green}{\text{rows}}$ using index(es)

$\color{green}{\text{distinct()}}$ - filter for unique $\color{green}{\text{rows}}$

$\color{green}{\text{sample_n()/sample_frac()}}$ - randomly sample $\color{green}{\text{rows}}$

</center>

# Pipes!
The `%>%` is the pipe operator. It passes the result on left into the first argument of the function on the right, or "pipes" the previous output as the input for the next function. Read it in your head as *then*

For example, if we just want the TotalValue and LotSize for homes in Scottsville arranged in descending order of LotSize, without the pipe, we'd:

```{r}
scottsville <- filter(homes, City == "SCOTTSVILLE")
scottsville <- select(scottsville, TotalValue, LotSize)
scottsville <- arrange(scottsville, desc(LotSize))
scottsville
```

With the pipe, we can start with homes, *then* filter only the rows for Scottsville, *then* select only the variables TotalValue and LotSize, *then* arrange the rows by descending order of LotSize.

```{r}
homes %>% 
  filter(City == "SCOTTSVILLE") %>% 
  select(TotalValue, LotSize) %>% 
  arrange(desc(LotSize))
```


## Keyboard Shortcut!

* Mac: cmd + shift + m
* Windows: ctrl + shift + m


# The Data
Let's take this to the raw data and start exploring it! It comes from the Albemarle county [Office of Geographic Data Services](http://www.albemarle.org/department.asp?department=gds&relpage=3914#Parcels), though the links are not currently visible.

The data includes

*  [Real Estate Information - Primary Card Level Data](http://people.virginia.edu/~mpc8t/dser/CAMA_CardLevelData.txt.htm)
* [Real Estate Information - Parcel Level Data](http://people.virginia.edu/~mpc8t/dser/CAMA_ParcelInfo.txt.htm)


# dplyr: Deriving data

<center>

$\color{blue}{\text{mutate()}}$ - create new $\color{blue}{\text{variables}}$

$\color{blue}{\text{summarize()}}$ - summarize $\color{blue}{\text{variables}}$ 

$\color{green}{\text{group_by()}}$ - group $\color{green}{\text{rows}}$

</center>

## mutate()
Create new columns.

```{r}
homes %>% 
  mutate(value_sqft = TotalValue/FinSqFt) %>% 
  select(YearBuilt, Condition, FinSqFt, TotalValue, City, value_sqft) %>% 
  arrange(desc(value_sqft))
```

We can create new variables as functions of other variables (ratios, conditions, ranks, etc.). We can mutate multiple variables in the same command.

```{r}
homes %>% 
  mutate(value_sqft = TotalValue/FinSqFt,
         remodel = if_else(YearRemodeled > 0, 1, 0)) %>% 
  select(value_sqft, remodel, City) %>% 
  arrange(value_sqft)
```

* `if_else(**condition, value_if_true, value_if_false, value_if_na**)`: mutate based on condition
* `case_when(condition1 ~ value1, 
            condition2 ~ value2, 
            condition3 ~ value3,
            TRUE ~ value_everything_else)`: vectorize multiple `if_else()` statements


## summarize()
Compute table of summaries.

```{r}
homes %>% 
  summarize(oldest = min(YearBuilt), 
            newest = max(YearBuilt), 
            total = n())
```

`summarize` takes a single vector as input (a variable) and returns a single value as output (the requested summary of the variable).

Summary functions include

* **first()**: first value
* **last()**: last value
* **nth(**.x, **n)**: nth value
* **n()**: number of values
* **n_distinct()**: number of distinct values
* **min()**: minimum value
* **max()**: maximum value
* **mean()**: mean value
* **median()**: median value
* **var()**: variance
* **sd()**: standard deviation
* **IQR()**: interquartile range

That's not always interesting on it's own, but when combined with `group_by`, it is powerful!

## group_by()
Groups cases by common values of one or more columns.

```{r}
homes %>% 
  group_by(City) %>% 
  summarize(oldest = min(YearBuilt), 
            newest = max(YearBuilt), 
            total = n())
```

## and more...

<center>

$\color{blue}{\text{tally()}}$ - short hand for `summarize(n())`

$\color{blue}{\text{count()}}$ - short hand for `group_by()` + `tally()`

$\color{blue}{\text{summarize_all()}}$ - apply summary function to all 
$\color{blue}{\text{variables}}$

$\color{blue}{\text{summarize_at()}}$ - apply summary function to selected $\color{blue}{\text{variables}}$

$\color{blue}{\text{rename()}}$ - rename $\color{blue}{\text{variables}}$

$\color{blue}{\text{recode()}}$ - modify values of $\color{blue}{\text{variables}}$

</center>

# Factors
Factors are variables  which take on a limited number of values, aka categorical variables. In R, factors are stored as a vector of integer values with the corresponding set of character values you'll see when displayed (colloquially, labels; in R, levels). 

```{r}
homes %>% count(Condition) # currently a character

homes %>% 
  mutate(condition = factor(Condition)) %>% # make a factor
  count(condition)

# assert the ordering of the factor levels
cond_levels <- c("Excellent", "Good", "Average", "Fair", "Poor", "Substandards")
homes %>% 
  mutate(condition = factor(Condition, levels = cond_levels)) %>% 
  count(condition)
```

## forcats

The [`forcats`](https://forcats.tidyverse.org/) package, part of the `tidyverse`, provides helper functions for working with factors. Including

* **fct_infreq()**: reorder factor levels by frequency of levels
* **fct_reorder()**: reorder factor levels by another variable
* **fct_relevel()**: change order of factor levels by hand
* **fct_recode()**: change factor levels by hand
* **fct_collapse()**: collapse factor levels into defined groups
* **fct_lump()**: collapse least/most frequent levels of factor into "other"


# dplyr: Joins 

Often, a single data set won't contain all of the information or attributes necessary to address your questions. Instead, we have to join or combine multiple data sets. The Albermarle homes data came from multiple data tables; and we could consider adding data from additional sources to answer yet more questions.

The variables used to connect data sets are called keys. A key (a single variable or multiple variables) uniquely identifies an observation. 

<center>

$\color{blue}{\text{Mutating joins}}$ use information from one data set to add $\color{blue}{\text{variables}}$ to another data set (like $\color{blue}{\text{mutate())}}$.

$\color{green}{\text{Filtering joins}}$ use information from one data set to extract $\color{green}{\text{rows}}$ from another data set (like $\color{green}{\text{filter())}}$.

</center>

The syntax is always `name_join(x, y, by = "key")`

## mutating joins

A visual explanation is in Grolemund's and Wickham's [R for Data Science](https://r4ds.had.co.nz/relational-data.html#understanding-joins).

* **full_join()**: keeps all observations in x and y
* **left_join()**: keeps all observations in x
* **right_join()**: keeps all observations in y
* **inner_join()**: keeps observations in both x and y


## filtering joins

Filtering joins match observations in the same way, but rather than adding variables, it extracts observations.

* **semi_join()**: keeps all observations in x that have a match in y
* **anti_join()**: drops all observations in x that have a match in y


# Resources

* RStudio's [dplyr cheat sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)
* Garrett Grolemund and Hadley Wickham. 2018. [R for Data Science](https://r4ds.had.co.nz/).
* [Finding Help](http://people.virginia.edu/~jah2ax/intro_to_R_spring_2019/intro_to_R_spring_2019.html#finding_help) resources from Introduction to R


